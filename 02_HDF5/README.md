# HDF5 포맷

## h5py 설치

확장자 `.hdf5`를 가지고 있는 파일은 대용량 데이터를 다루기 위한 데이터 포맷입니다. 다음과 같이 파이썬 모듈을 설치할 수 있습니다.

```bash
pip install h5py
```

## 파일 읽어오기

`hdf5`파일은 다음과 같이 읽어올 수 있습니다.

```python
d5py.File('파일경로', '생성여부')
```

가져올 파일의 경로와 생성여부를 부여합니다. 생성여부는 `r`을 작성할 경우에 파일을 참조만하고, `w`를 작성할 경우 파일을 작성합니다. 

## 데이터 받기

<https://data.mendeley.com/datasets/pvn3xc3wy5/1>에 있는 CaloGAN 데이터가 어떤 정보를 담고 있는지 확인하겠습니다. 세개의 데이터가 있는데, `gamma(photon)`과 `eplus(positron)`만 다운로드해서 사용하겠습니다.

```python
import h5py
import numpy as np

d_gamma = h5py.File('data/gamma.hdf5', 'r')
d_eplus = h5py.File('data/eplus.hdf5', 'r')

gamma_energy = d_gamma['energy'][:]
gamma_0 = d_gamma['layer_0'][:]
gamma_1 = d_gamma['layer_1'][:]
gamma_2 = d_gamma['layer_2'][:]

eplus_energy = d_eplus['energy'][:]
eplus_0 = d_eplus['layer_0'][:]
eplus_1 = d_eplus['layer_1'][:]
eplus_2 = d_eplus['layer_2'][:]

print (eplus_0)
```

하나의 데이터는 객체로 구성되어 있고 layer1, layer2, layer3 3가지 종류로 나뉘어져 있습니다. 이는 ATLAS Calorimeter의 특성상 구역 3개를 layer로 나누어 놓은 것입니다. energy는 초기입자의 에너지입니다.

```
{
    "layer_0": 
    [[[ 0.          0.          0.         ...,  0.          0.          0.088005  ]
      [ 0.          0.          0.         ...,  0.          0.          0.        ]
      [ 0.          0.          0.         ...,  0.          0.          0.        ]]

     [[ 0.          0.          0.         ...,  0.          0.          0.        ]
      [ 0.77804506  0.46968224  2.23565433 ...,  0.5954982   0.          0.10002631]
      [ 0.          0.          0.         ...,  0.          0.          0.        ]]

     [[ 0.01374402  0.          0.76326864 ...,  0.          0.          0.        ]
      [ 0.          0.          1.8273663  ...,  0.81162041  0.          0.        ]
      [ 0.41695712  4.45745789  0.         ...,  0.          0.          0.        ]]

     ...,
     [[ 0.          0.          0.         ...,  0.00677904  0.          0.        ]
      [ 0.          0.          0.         ...,  0.          0.          0.4343341 ]
      [ 0.          0.          0.         ...,  0.          0.          0.        ]]

     [[ 0.          0.          0.         ...,  0.          0.15767991
        0.353319  ]
      [ 0.          0.          0.         ...,  0.63053016  0.          0.        ]
      [ 0.          0.          0.         ...,  0.          0.          0.        ]]

     [[ 0.          0.          0.         ...,  0.          0.          0.        ]
      [ 0.          0.          0.         ...,  0.          0.          0.        ]
      [ 0.          0.          0.         ...,  0.          0.          0.        ]]]
    ,
    "layer_1": [...],
    "layer_2": [...],
}
```

`layer_0`의 데이터는 위 `print (eplus_0)`의 결과물입니다. 그리고 d_eplus는 위와 같이 생겼을 것입니다. `layer_0`을 보니 수많은 데이터가 하나의 row를 이루고 있고 그 row가 3개의 column으로 이루어져 있으며, 이런 묶음이 여러개 나열되어 있습니다. `layer_0`의 shape을 확인해보죠.

```python
print (eplus_0.shape)
##(100000, 3, 96)
```

데이터 설명을 보면, **calorimeter에서 일어나는 100,000개의 shower를 측정했다고 되어 있습니다. 100,000개의 샤워가 3x96 데이터를 담고 있는 것입니다.** 

```python
print (eplus_1.shape)
##(100000, 12, 12)
```

`layer_1`은 12x12 데이터가 100,000개 쌓여있는 데이터이므로 정방형 이미지를 추출됩니다.

```python
print (eplus_2.shape)
##(100000, 12, 6)
```

`layer_2`는 12x6의 데이터가 추출됩니다. 



## Sparsity

9x9의 이미지가 있을 때, 신호가 들어온 곳만 모아서 전체 셀 81개로 나누어 `sparsity`를 구합니다. 예를들어 2x2인 4개의 이미지 3개라고 가정했을 때 sparsity를 구해보면 다음과 같습니다.

```python
signal = np.array([[0,2,1,1], [2,0,1,0], [3,0,0,0]])
## signal이 있는 것(x>0)만 모아서 평균을 냄
sparsity = map(lambda x: (x>0).mean(), signal)

## output: [0.75, 0.5, 0.25]
```

첫번째 이미지는 signal이 75%, 두번재 이미지는 50%, 세번째 이미지는 25%로 signal이 확인되므로 **particle shower가 얼마나 멀리 퍼져있는 것을 알 수 있습니다.**

